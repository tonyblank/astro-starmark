# Astro Docs Feedback Plugin Development Rules

## Project Overview
This is an Astro/Starlight documentation feedback plugin with:
- Persistent feedback widget (floating bottom-right)
- Text highlighting & annotation capabilities
- Feedback form with categories and tags
- Pluggable storage backends (Linear primary, Astro DB, Cloudflare D1)
- Modular authentication system (Auth0 initially)
- Built using Astro Islands architecture for performance

## Architecture Principles

### Core Technology Stack
- Pure Astro/vanilla JS/TypeScript (NO React)
- Astro Islands for client-side interactivity
- PNPM workspace monorepo with Turborepo for build orchestration
- **Modern Testing Stack (2025):**
  - **Vitest**: Primary test runner (unit, component, integration)
  - **MSW v2**: API mocking with Request/Response API
  - **Playwright**: E2E testing with real browser automation
  - **Testing Library**: Component testing utilities
- GitHub Actions for CI/CD

### Project Structure
```
astro-docs-feedback/           # Core plugin package
├── src/
│   ├── client/                # Client-side components
│   │   ├── FeedbackWidget.astro
│   │   ├── FeedbackModal.astro
│   │   └── highlight.ts
│   ├── server/                # Server-side logic
│   │   ├── feedbackEndpoint.ts
│   │   ├── LinearConnector.ts
│   │   ├── AstroDbConnector.ts
│   │   ├── D1Connector.ts
│   │   └── Auth.ts
│   └── translations/          # i18n strings
└── tests/                     # Unit and integration tests

docs-site/                     # Marketing/docs site + test environment
├── src/
│   ├── content/docs/          # Plugin documentation
│   └── pages/api/             # Test API endpoints
├── tests/                     # E2E tests for the site
└── public/                    # Static assets
```

## Test-Driven Development Rules

### Testing Philosophy
1. **ALWAYS write tests BEFORE implementation** - This is strict TDD
2. **Test interfaces, not implementations** - Focus on behavior
3. **High test coverage required** - Aim for >90%, critical paths 100%
4. **Test error conditions** - Don't just test happy paths

### Streamlined Testing Stack (2025)

#### Core Testing Tools
- **Vitest**: Primary test runner with native ES modules support
- **Playwright**: E2E testing with modern browser support
- **MSW v2**: API mocking with Request/Response API
- **Testing Library**: Component testing utilities
- **@astrojs/test-utils**: Astro-specific testing helpers

#### Additional Infrastructure
- **Turborepo**: Monorepo task orchestration and caching
- **GitHub Actions**: CI/CD with matrix testing across Node versions
- **Codecov**: Coverage reporting and analysis
- **Changesets**: Version management and changelog generation

### When to Mock vs Real Implementation

#### ALWAYS Mock:
- External HTTP APIs (Linear GraphQL API, Auth0 endpoints)
- Network requests using MSW (Mock Service Worker)
- Browser APIs in unit tests (window.getSelection, etc.)
- Authentication tokens/JWT verification
- Time-sensitive operations (Date.now, setTimeout)

#### NEVER Mock (Use Real):
- Astro component rendering (use @astrojs/test-utils)
- SQLite database operations (use in-memory DB or temp files)
- DOM manipulation in integration tests
- TypeScript compilation and type checking
- CSS/SCSS compilation

#### Conditional Mocking:
- Astro DB: Mock the `db` object methods OR use real SQLite connection
- File system operations: Mock in unit tests, real in integration tests
- Environment variables: Mock in tests, real in E2E

### Testing Layers

#### 1. Unit Tests (Vitest)
```typescript
// Test individual functions/classes in isolation
// Mock all external dependencies
// Focus on business logic and edge cases
// Run with: pnpm test:unit
```

#### 2. Component Tests (Vitest + Testing Library)
```typescript
// Test component behavior and user interactions
// Use @astrojs/test-utils for Astro components
// Test accessibility and keyboard navigation
// Develop components directly in docs-site
// Run with: pnpm test:component
```

#### 3. Integration Tests (Vitest + MSW)
```typescript
// Test component interactions and API flows
// Mock external APIs but use real internal components
// Test full request/response cycles
// Run with: pnpm test:integration
```

#### 4. E2E Tests (Playwright)
```typescript
// Test complete user workflows in real browser
// Test against the docs-site with real plugin integration
// Minimal mocking (only external APIs if needed)
// Run with: pnpm test:e2e
```

## Component Development Patterns

### Astro Components
- Use Astro's native JSX/TSX syntax
- Hydrate components with appropriate strategies:
  - `client:idle` for feedback widget
  - `client:visible` for modals
  - `client:load` only when necessary
- Keep components small and focused
- Use TypeScript interfaces for props
- Develop and test components directly in docs-site

### State Management
- NO external state libraries
- Use Astro's built-in reactivity
- DOM APIs for simple state (selected text, modal open/close)
- Custom events for component communication
- Web Components for complex interactive elements

### Styling
- Use Starlight's CSS variables for theming
- Scoped styles in Astro components
- NO global CSS overrides
- Support dark/light mode automatically
- CSS Container Queries for responsive design

## Data Flow Architecture

### Frontend Submission Flow
1. User interaction (widget click, text selection, form submission)
2. Client-side validation and data collection
3. POST to `/api/feedback` endpoint
4. Show loading state, handle success/error responses

### Backend Processing Flow
1. Validate request data with Zod schemas
2. Extract user authentication (if present)
3. Process through configured connectors in parallel:
   - LinearConnector.store()
   - AstroDbConnector.store()
   - D1Connector.store() (if configured)
4. Return unified response with proper error handling

### Connector Pattern
```typescript
interface FeedbackStorage {
  store(feedback: FeedbackData): Promise<StorageResult>;
}

interface StorageResult {
  success: boolean;
  id?: string;
  error?: Error;
}
```
- Each connector implements this interface
- Connectors are independent and can fail individually
- Use dependency injection for testing
- Proper error handling and logging

## Error Handling Standards

### Client-Side
- Always provide user feedback (loading states, success/error messages)
- Graceful degradation if JavaScript disabled
- Handle network failures with retry options
- Log errors to external service in production

### Server-Side
- Log errors but don't expose internals to client
- Continue processing if one connector fails
- Use appropriate HTTP status codes
- Structured logging with correlation IDs

### Testing Error Conditions
- Network timeouts and failures
- Invalid/malicious input data
- Authentication failures
- Database connection issues
- Rate limiting scenarios

## Development Workflow

### Before Starting Any Feature
1. Write failing test that describes expected behavior
2. Run test to confirm it fails for the right reason
3. Implement minimal code to make test pass
4. Refactor while keeping tests green
5. Add edge case tests

### Code Quality Gates
- All tests must pass (`pnpm test`)
- ESLint/Prettier compliance (`pnpm lint`)
- TypeScript compilation without errors (`pnpm type-check`)
- Generated code type-safety validation (`pnpm type-check:generated`)
- No console.log statements in production code
- Accessibility standards met (automated testing with axe)
- Performance budgets met (Core Web Vitals)

### Commit Standards
- Each commit should have passing tests
- Use conventional commit messages
- Include test files in commits
- Keep commits atomic and focused
- Run `pnpm changeset` for version changes

### Branch Strategy
- `main`: Production-ready code
- `develop`: Integration branch for features
- `feature/*`: Individual feature branches
- Each milestone gets its own feature branch
- PR must pass all CI checks and AI agent code review before merge

## Authentication Integration

### Auth0 Implementation
- Store credentials server-side only
- Validate tokens on server before processing
- Support anonymous feedback by default
- Graceful fallback if auth service unavailable
- Use Auth0 SPA SDK for client-side integration
- Test with Auth0 free plan in docs-site

### Modular Auth Design
```typescript
interface AuthProvider {
  getCurrentUser(request: Request): Promise<UserInfo | null>;
  validateToken(token: string): Promise<boolean>;
}
```

## Performance Requirements

### Bundle Size
- Plugin core < 50KB gzipped
- Client-side code < 20KB gzipped
- Use dynamic imports for non-critical features
- Tree-shake unused code

### Runtime Performance
- Widget should not block page load (< 100ms impact)
- Feedback submission under 2s normal conditions
- No layout shifts when widget appears (CLS < 0.1)
- Core Web Vitals: LCP < 2.5s, FID < 100ms

### Memory Usage
- Clean up event listeners properly
- Remove temporary DOM elements after use
- No memory leaks in long-running sessions
- Monitor with performance.measureUserAgentSpecificMemory()

## Accessibility Requirements

### WCAG 2.2 AA Compliance
- All interactive elements keyboard accessible
- Proper ARIA labels and roles
- Color contrast ratios ≥ 4.5:1
- Screen reader friendly
- Focus indicators visible
- No seizure-inducing animations

### Modal Accessibility
- Focus management (trap focus, return focus)
- ESC key closes modal
- Backdrop click closes modal
- ARIA attributes for modal state
- Scroll lock when modal is open

## Deployment & Distribution

### Package Configuration
- Proper peer dependencies for Astro/Starlight
- TypeScript declarations included
- Tree-shakeable exports (ESM only)
- Support Node.js 18+ and latest browsers
- Semantic versioning with changesets

### Documentation Requirements
- Comprehensive README with examples
- API documentation generated from TypeScript
- Interactive examples in docs-site
- Migration guides for breaking changes
- Troubleshooting section with common issues

## Debugging Guidelines

### Development Debugging
- Use DEBUG environment variable for verbose logging
- Include request/response logging in dev mode
- Provide clear error messages with context
- Source maps for debugging production builds

### Production Debugging
- No sensitive data in logs
- Structured logging with correlation IDs
- Error tracking with Sentry or similar
- Performance monitoring with Real User Monitoring

## Security Considerations

### Data Handling
- Sanitize all user input with DOMPurify
- No PII in logs unless explicitly needed
- Secure storage of API keys and tokens
- Content Security Policy headers

### API Security
- Rate limiting on feedback endpoint (10 req/min per IP)
- CSRF protection with tokens
- Input validation with Zod schemas
- SQL injection prevention

### Privacy
- Anonymous feedback by default
- Clear data retention policies (90 days default)
- GDPR compliance for EU users
- Cookie consent for analytics

## Integration Testing Strategy

### Component Integration
- Test widget + modal interaction in docs-site
- Test highlight selection + form integration
- Test form submission + server response handling
- Test auth flow with mocked Auth0

### Storage Integration
- Test all connector combinations
- Test partial failure scenarios
- Test data consistency across connectors
- Test with real databases in integration environment

### Authentication Integration
- Test logged-in vs anonymous users
- Test token validation and refresh
- Test auth provider failures
- Test session management

## CI/CD Pipeline

### GitHub Actions Workflow
1. **Install & Cache**: Install dependencies with pnpm, cache node_modules
2. **Lint & Type Check**: Run ESLint, Prettier, TypeScript compiler
3. **Unit Tests**: Run Vitest with coverage reporting
4. **Component Tests**: Run component tests with Testing Library
5. **Integration Tests**: Run API tests with MSW
6. **E2E Tests**: Run Playwright tests against docs-site
7. **Build**: Build all packages and ensure no errors
8. **Release**: Generate changesets and publish to npm (on main)

### Quality Gates
- Test coverage ≥ 90%
- All linting rules pass
- No TypeScript errors
- No accessibility violations
- Performance budgets met
- Security vulnerabilities resolved
- AI agent code review approval

Remember: Every feature starts with a failing test. Every bug fix starts with a test that reproduces the issue. No exceptions.

## Core Development Rules

### Work Tracking & Documentation
- **ALWAYS update .cursor/context with milestone progress and work summaries**
- **NEVER create additional markdown files for project tracking - use .cursor/ folder only**
- Document all completed work with:
  - Files created/modified
  - Technical achievements
  - Key design decisions
  - Known issues to address in next session
- Update milestone status with ✅ when complete, 🚧 when in progress
- Add work summary section at the end of each completed milestone

### Code Quality & Testing
- Follow TDD approach: write tests first, then implement
- All builds must pass before considering milestone complete
- Maintain comprehensive test coverage (aim for >90%)
- Use modern tooling: Vitest, Playwright, MSW v2, TypeScript strict mode
- Implement graceful error handling that doesn't break builds

### Project Structure
- Use monorepo with PNPM workspaces + Turborepo
- Keep packages isolated with proper peer dependencies
- Follow ESM-first approach with proper TypeScript exports
- Use Zod for runtime validation with graceful degradation

### Communication & AI Assistance
- Always explain what each tool call accomplishes
- Run parallel tool calls for maximum efficiency
- Update context before ending sessions
- Ask clarifying questions if requirements are unclear
- Maintain detailed progress tracking in .cursor/context

## AI Tool Usage Guidelines

### Tool Call Efficiency
- **ALWAYS run parallel tool calls when possible** (e.g., reading multiple files, running independent commands)
- Prioritize parallel execution over sequential operations
- Use parallel calls for read-only operations like file reading, grep searches, codebase searches
- Group related operations together in single calls when beneficial

### File Operations
- Use `edit_file` for all code changes instead of outputting code to user
- Make all edits to a file in a single `edit_file` call rather than multiple calls
- Use `// ... existing code ...` to represent unchanged sections
- Provide clear instructions describing the edit purpose

### Code Implementation
- Ensure generated code can run immediately without additional steps
- Add all necessary imports, dependencies, and configuration
- Create appropriate dependency management files (package.json, requirements.txt)
- For web apps, implement modern UI with good UX practices
- Never generate extremely long hashes or binary content
- Fix linter errors if clear how to, but don't loop more than 3 times on same file

### Error Handling
- If suggested code_edit isn't followed properly, try reapplying the edit
- Don't make uneducated guesses about fixes
- Stop and ask user for guidance after 3 failed attempts at same issue

## Project-Specific Rules

### StarMark Development
- Always maintain the StarMark integration as dogfooding example in starmark.dev
- Keep integration gracefully failing - never break builds
- Test integration loads without errors as primary success criteria
- Use Starlight for documentation with proper sidebar navigation
- Follow the milestone checklist in .cursor/context strictly

### Testing Requirements
- Unit tests: Vitest with globals, ESM modules
- Component tests: Vitest + Testing Library for Astro components
- Integration tests: Vitest + MSW v2 for API mocking
- E2E tests: Playwright with modern selectors and auto-waiting
- All tests must be isolated and not depend on external services

### Build System
- Use Turborepo for build orchestration
- Configure proper caching and dependency management
- Support Node.js 18+ with modern ESM
- Generate TypeScript declarations for all packages
- Use tsup for library builds, Astro for site builds

## Modern Stack Conventions

### TypeScript Configuration
- Use strict mode with all type checking enabled
- Target ES2022 with modern module resolution
- Generate source maps and declaration files
- Use proper module bundling (bundler resolution)

### Package Management
- Use PNPM workspaces for monorepo structure
- Specify exact peer dependencies
- Use workspace:* for internal package references
- Include proper files field in package.json

### CI/CD Pipeline
- Test across Node.js 18, 20, 22
- Test on Ubuntu, Windows, macOS
- Include security audits and dependency checks
- Upload test artifacts and coverage reports
- Use matrix strategy for comprehensive testing

### Code Style
- Use Prettier for formatting with modern options
- ESLint with TypeScript and Astro plugins
- Follow semantic versioning with changesets
- Use conventional commits for clear history

## Error Recovery Patterns

### Common Issues
- Missing browser installations for Playwright (run `playwright install`)
- TypeScript config errors (check extends paths and types)
- Build cache issues (clear with `pnpm clean`)
- Dependency resolution (ensure proper peer deps)

### Debugging Steps
1. Check linter errors for obvious fixes
2. Verify all dependencies are installed
3. Clear build caches if builds fail mysteriously
4. Check TypeScript config paths and extends
5. Ensure proper ESM imports/exports

### When to Ask for Help
- After 3 failed attempts at same fix
- When requirements are ambiguous
- When user needs to make architectural decisions
- When external services or credentials are needed

## Session Management

### Starting Sessions
- Review .cursor/context for current state
- Check completed milestones and next tasks
- Identify any known issues from previous session

### Ending Sessions
- Update .cursor/context with progress made
- Document any new issues discovered
- Mark milestones as complete with work summary
- Note next steps and priorities

### Handoff Quality
- Ensure another AI could continue work seamlessly
- Document all design decisions and rationale
- Include specific commands needed for next steps
- Update checklist with current status 